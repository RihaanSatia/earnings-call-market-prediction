


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
import os


print(os.getcwd())


sys.path.append('../src')
plt.style.use('default')
sns.set_palette("husl")


# Load raw data
data_dir = Path('../data/raw')

transcripts = pd.read_csv(data_dir / 'earnings_calls_transcripts.csv')
sentiment = pd.read_csv(data_dir / 'earnings_calls_transcript_sentiment.csv')
prices = pd.read_csv(data_dir / 'earnings_calls_stock_prices.csv')





transcripts.head()


sentiment.head()


prices.head()


print(f"Transcripts: {transcripts.shape}")
print(f"Sentiment: {sentiment.shape}")
print(f"Prices: {prices.shape}")


# Dataset overview
transcripts['date'] = pd.to_datetime(transcripts['date'])
sentiment['date'] = pd.to_datetime(sentiment['date'])
prices['date'] = pd.to_datetime(prices['date'])

print("=== TRANSCRIPTS ===")
print(f"Companies: {transcripts['company'].nunique()}")
print(f"Date range: {transcripts['date'].min()} to {transcripts['date'].max()}")
print(f"Companies: {transcripts['company'].unique()}")


print("\n=== SENTIMENT ===")
print(f"Companies: {sentiment['company'].nunique()}")
print(f"Date range: {sentiment['date'].min()} to {sentiment['date'].max()}")
print(f"Sentiment labels: {sentiment['label'].value_counts().to_dict()}")


print("\n=== PRICES ===")
print(f"Companies: {prices['company'].nunique()}")
print(f"Date range: {prices['date'].min()} to {prices['date'].max()}")


# Transcript analysis
transcripts['transcript_length'] = transcripts['transcript'].str.len()
transcripts['word_count'] = transcripts['transcript'].str.split().str.len()

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

transcripts['transcript_length'].hist(bins=20, ax=axes[0])
axes[0].set_title('Transcript Character Length')
axes[0].set_xlabel('Characters')

transcripts['word_count'].hist(bins=20, ax=axes[1])
axes[1].set_title('Transcript Word Count')
axes[1].set_xlabel('Words')

plt.tight_layout()
plt.show()


print(f"Avg transcript length: {transcripts['transcript_length'].mean():.0f} chars")
print(f"Avg word count: {transcripts['word_count'].mean():.0f} words")


# Sentiment distribution
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
sentiment['label'].value_counts().plot(kind='bar', ax=axes[0])
axes[0].set_title('Overall Sentiment Distribution')
axes[0].set_ylabel('Count')
axes[0].tick_params(axis='x', rotation=45)

sentiment_time = sentiment.groupby([sentiment['date'].dt.year, 'label']).size().unstack(fill_value=0)
sentiment_time.plot(kind='bar', stacked=True, ax=axes[1])
axes[1].set_title('Sentiment Over Time')
axes[1].set_xlabel('Year')
axes[1].set_ylabel('Count')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()


# Stock price analysis
prices_analysis = prices.copy()
prices_analysis = prices_analysis.sort_values(['company', 'date'])
prices_analysis['daily_return'] = prices_analysis.groupby('company')['adj_close'].pct_change()
prices_analysis['volatility'] = prices_analysis.groupby('company')['daily_return'].rolling(10).std().reset_index(0, drop=True)


fig, axes = plt.subplots(2, 2, figsize=(12, 8))

for company in prices_analysis['company'].unique():
  company_data = prices_analysis[prices_analysis['company'] == company]
  axes[0,0].plot(company_data['date'], company_data['adj_close'], label=company, alpha=0.7)
axes[0,0].set_title('Stock Prices Over Time')
axes[0,0].set_ylabel('Adjusted Close Price')
axes[0,0].legend()

prices_analysis['daily_return'].dropna().hist(bins=50, ax=axes[0,1])
axes[0,1].set_title('Daily Returns Distribution')
axes[0,1].set_xlabel('Daily Return')

for company in prices_analysis['company'].unique():
  company_data = prices_analysis[prices_analysis['company'] == company]
  axes[1,0].plot(company_data['date'], company_data['volatility'], label=company, alpha=0.7)
axes[1,0].set_title('Volatility Over Time')
axes[1,0].set_ylabel('10-day Rolling Volatility')
axes[1,0].legend()

prices_analysis['volume'].hist(bins=30, ax=axes[1,1])
axes[1,1].set_title('Trading Volume Distribution')
axes[1,1].set_xlabel('Volume')

plt.tight_layout()
plt.show()


print("=== DATA COVERAGE ===")

transcript_companies = set(transcripts['company'].unique())
sentiment_companies = set(sentiment['company'].unique())
price_companies = set(prices['company'].unique())
print(f"Companies in transcripts: {transcript_companies}")
print(f"Companies in sentiment: {sentiment_companies}")
print(f"Companies in prices: {price_companies}")
all_three = transcript_companies & sentiment_companies & price_companies
print(f"\nCompanies in all three datasets: {all_three}")


for company in all_three:
  t_dates = transcripts[transcripts['company'] == company]['date']
  s_dates = sentiment[sentiment['company'] == company]['date']
  p_dates = prices[prices['company'] == company]['date']

  t_min = t_dates.min().strftime('%Y-%m-%d') 
  t_max = t_dates.max().strftime('%Y-%m-%d') 
  s_min = s_dates.min().strftime('%Y-%m-%d') 
  s_max = s_dates.max().strftime('%Y-%m-%d') 
  print(f"\n{company}:")
  print(f"  Transcripts: {t_min} to {t_max} ({len(t_dates)} calls)")
  print(f"  Sentiment: {s_min} to {s_max} ({len(s_dates.unique())} unique dates)")


sample_transcript


# Sample transcript analysis
sample_transcript = transcripts.iloc[0]
print(f"Company: {sample_transcript['company']}")
print(f"Date: {sample_transcript['date']}")

print(f"\nFirst 5000 characters:")
print(sample_transcript['transcript'][:5000])


same_call_sentiment = sentiment[
  (sentiment['company'] == sample_transcript['company']) &
  (sentiment['date'] == sample_transcript['date'])
]
print(f"\nSentiment paragraphs for this call: {len(same_call_sentiment)}")
print(same_call_sentiment['label'].value_counts())


# Summary statistics
print("=== DATASET SUMMARY ===")
print(f"Total earnings calls: {len(transcripts)}")
print(f"Companies covered: {len(all_three)}")
print(f"Time period: {transcripts['date'].min().year}-{transcripts['date'].max().year}")
print(f"Total sentiment paragraphs: {len(sentiment)}")
print(f"Stock price data points: {len(prices)}")

returns = prices_analysis['daily_return'].dropna()
volatility = prices_analysis['volatility'].dropna()

high_vol_threshold = volatility.quantile(0.75)
high_return_threshold = 0.02

print(f"\n=== POTENTIAL TARGETS ===")
print(f"High volatility threshold (75th percentile): {high_vol_threshold:.4f}")
print(f"Significant return threshold: Â±{high_return_threshold:.1%}")
print(f"Days with high volatility: {(volatility > high_vol_threshold).sum()} ({(volatility > high_vol_threshold).mean():.1%})")
print(f"Days with significant returns: {(returns.abs() > high_return_threshold).sum()} ({(returns.abs() > 
high_return_threshold).mean():.1%})")



